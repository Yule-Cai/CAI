import os
from openai import OpenAI

class LMStudioService:
    def __init__(self):
        # é»˜è®¤è¿æ¥æœ¬åœ° LM Studio
        self.base_url = "http://localhost:1234/v1"
        self.api_key = "lm-studio" # æœ¬åœ°æœåŠ¡é€šå¸¸ä¸éœ€è¦çœŸå® Key
        
        try:
            self.client = OpenAI(base_url=self.base_url, api_key=self.api_key)
            # ğŸŸ¢ è‡ªåŠ¨è·å–å½“å‰åŠ è½½çš„æ¨¡å‹ ID
            self.model_id = self._fetch_current_model()
            print(f"[LLM] Connected. Target Model: {self.model_id}")
        except Exception as e:
            print(f"[LLM] Connection Failed: {e}")
            self.model_id = "local-model" # é™çº§æ–¹æ¡ˆ

    def _fetch_current_model(self):
        """ å‘ LM Studio è¯¢é—®å½“å‰åŠ è½½äº†ä»€ä¹ˆæ¨¡å‹ """
        try:
            models = self.client.models.list()
            if models.data:
                # è¿”å›ç¬¬ä¸€ä¸ªåŠ è½½çš„æ¨¡å‹ ID
                return models.data[0].id
        except:
            pass
        return "local-model"

    def get_model_id(self):
        return self.model_id