import sherpa_onnx
import sounddevice as sd
import numpy as np
import sys
import os
import time

class SherpaASRService:
    def __init__(self):
        model_dir = "asr_model"
        
        # 1. æ£€æŸ¥æ–‡ä»¶
        required_files = ["encoder.onnx", "decoder.onnx", "joiner.onnx", "tokens.txt"]
        for f in required_files:
            path = f"{model_dir}/{f}"
            if not os.path.exists(path):
                raise FileNotFoundError(f"âŒ å¬åŠ›ç³»ç»ŸæŸå: æ‰¾ä¸åˆ° {path}ã€‚è¯·ç¡®è®¤ä½ å·²æ¸…ç©º asr_model æ–‡ä»¶å¤¹å¹¶é‡æ–°ä¸‹è½½äº†æ¨¡å‹ï¼Œä¸”å®Œæˆäº†æ–‡ä»¶é‡å‘½åï¼")

        print(f"[ASR] æ­£åœ¨åŠ è½½å¬åŠ›æ¨¡å‹ (Bilingual)...")
        
        # 2. åŠ è½½æ¨¡å‹
        try:
            self.recognizer = sherpa_onnx.OnlineRecognizer.from_transducer(
                tokens=f"{model_dir}/tokens.txt",
                encoder=f"{model_dir}/encoder.onnx",
                decoder=f"{model_dir}/decoder.onnx",
                joiner=f"{model_dir}/joiner.onnx",
                num_threads=1,
                sample_rate=16000,
                feature_dim=80,
                decoding_method="greedy_search",
            )
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ æç¤ºï¼šå¯èƒ½æ˜¯æ–‡ä»¶æŸåæˆ– tokens.txt ä¸æ¨¡å‹ä¸åŒ¹é…ã€‚")
            raise e

        print("[ASR] è€³æœµå·²ä¿®å¤å¹¶å°±ç»ªã€‚")

    def listen(self):
        """
        ç›‘å¬éº¦å…‹é£
        """
        stream = self.recognizer.create_stream()
        sample_rate = 16000
        chunk_size = 1024 
        
        print("\n[ğŸ‘‚] æ­£åœ¨å¬... (è¯·è¯´è¯)")
        
        last_text = ""
        last_change_time = 0
        silence_threshold = 1.0 # åœé¡¿ 1 ç§’åˆ¤å®šä¸ºè¯´å®Œ
        
        with sd.InputStream(channels=1, dtype="float32", samplerate=sample_rate) as s:
            while True:
                samples, _ = s.read(chunk_size)
                samples = samples.reshape(-1)
                stream.accept_waveform(sample_rate, samples)
                while self.recognizer.is_ready(stream):
                    self.recognizer.decode_stream(stream)
                
                text = self.recognizer.get_result(stream)
                
                if text:
                    sys.stdout.write(f"\r[æ­£åœ¨å¬]: {text}")
                    sys.stdout.flush()
                    
                    if text != last_text:
                        last_text = text
                        last_change_time = time.time()
                    else:
                        if (time.time() - last_change_time) > silence_threshold:
                            print(f"\n[æ£€æµ‹åˆ°åœé¡¿]: æäº¤ç»“æœã€‚")
                            return text
                            
                # åŒé‡æ–­å¥ä¿é™©
                if self.recognizer.is_endpoint(stream):
                    final_text = self.recognizer.get_result(stream)
                    if final_text.strip():
                        print(f"\n[è‡ªåŠ¨æ–­å¥]: {final_text}")
                        return final_text
                    else:
                        self.recognizer.reset(stream)